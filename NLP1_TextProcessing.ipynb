{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkwNGz9cfN4t",
        "outputId": "4a1f31ef-64ff-44b8-ba84-36c4a5552b98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.8.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk) (4.65.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk) (8.1.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"omw-1.4\")\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import re"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpUTRcQJfOkJ",
        "outputId": "61f9a346-110b-47ec-931a-fbb774adb883"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Data\n",
        "para=\"\"\"‚Äî Tensor and Tensorflow: A powerful combo üí™\n",
        "The Google Brain team developed an advanced AI framework named Tensorflow years back. After that, Google designed its own processing unit named Tensor Processing Unit or TPU to perform more efficiently with the Tensorflow. The invention of TPU was a revolution in AI that has significantly expedited the training of huge machine learning models with millions (or, billions) of parameters. Nevertheless, that technology could not be used in low-power devices such as smartphones in Edge AI. The entrance of Google into the AI chip manufacturing club for low-power devices can be the next revolution in this industry. Many companies such as FogHorn and BlinkAI are working in Edge AI using currently existing AI chips in the market. However, the efficacy that Google can create by the combination of TensorFlow and Tensor will be game-changing. Welcome to the club, Google!\n",
        "\n",
        "‚Äî Tensor is an AI chip designed by AI! üò≤\n",
        "Isn‚Äôt that cool? The story is started from an article published in Nature titles ‚ÄúA graph placement methodology for fast chip design‚Äù. To design a processing chip, there is a crucial step referred to as ‚Äúfloor planning‚Äù where the engineering team must place a large number of components such that a series of physical requirements including power consumption and performance get satisfied. I don‚Äôt go further into its details as I am also not an expert in hardware engineering. However, when you have a large series of choices to make with a series of constraints AI can kick in. You may remember how the AlphaGo project defeated a professional human Go player. This is exactly the same. Tensor is the real outcome of this project that is a new milestone in the AI industry. Kudos, Google!\n",
        "\n",
        "‚Äî Tensor helps us build ethical AI. üí°\n",
        "This is a double-edged sword statement. Ethical AI has various aspects from data privacy to AI for all. Tensor helps many users have the opportunity to try the latest AI advancement while they have no concern about their privacy. Why? Because the AI engine is running on the chip, and no data is sent to the cloud for further computation. On the other hand, the more tightly Google binds AI software and hardware, the harder it will be for other companies to compete. I don‚Äôt want to see days that other companies can not even compete on performing AI inference, i.e., compete on using AI. We almost lost the game of model training to giant tech companies. It would be a nightmare if we lose the game on AI inference to them as well. That is why I believe ‚ÄúTensor helps us build ethical AI‚Äù is a double-edged sword.\"\"\""
      ],
      "metadata": {
        "id": "sbAu7754fOmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "para"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "x3W3D9SEfOpP",
        "outputId": "b81fe369-5bff-4eaa-a005-a167bcc29ff4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'‚Äî Tensor and Tensorflow: A powerful combo üí™\\nThe Google Brain team developed an advanced AI framework named Tensorflow years back. After that, Google designed its own processing unit named Tensor Processing Unit or TPU to perform more efficiently with the Tensorflow. The invention of TPU was a revolution in AI that has significantly expedited the training of huge machine learning models with millions (or, billions) of parameters. Nevertheless, that technology could not be used in low-power devices such as smartphones in Edge AI. The entrance of Google into the AI chip manufacturing club for low-power devices can be the next revolution in this industry. Many companies such as FogHorn and BlinkAI are working in Edge AI using currently existing AI chips in the market. However, the efficacy that Google can create by the combination of TensorFlow and Tensor will be game-changing. Welcome to the club, Google!\\n\\n‚Äî Tensor is an AI chip designed by AI! üò≤\\nIsn‚Äôt that cool? The story is started from an article published in Nature titles ‚ÄúA graph placement methodology for fast chip design‚Äù. To design a processing chip, there is a crucial step referred to as ‚Äúfloor planning‚Äù where the engineering team must place a large number of components such that a series of physical requirements including power consumption and performance get satisfied. I don‚Äôt go further into its details as I am also not an expert in hardware engineering. However, when you have a large series of choices to make with a series of constraints AI can kick in. You may remember how the AlphaGo project defeated a professional human Go player. This is exactly the same. Tensor is the real outcome of this project that is a new milestone in the AI industry. Kudos, Google!\\n\\n‚Äî Tensor helps us build ethical AI. üí°\\nThis is a double-edged sword statement. Ethical AI has various aspects from data privacy to AI for all. Tensor helps many users have the opportunity to try the latest AI advancement while they have no concern about their privacy. Why? Because the AI engine is running on the chip, and no data is sent to the cloud for further computation. On the other hand, the more tightly Google binds AI software and hardware, the harder it will be for other companies to compete. I don‚Äôt want to see days that other companies can not even compete on performing AI inference, i.e., compete on using AI. We almost lost the game of model training to giant tech companies. It would be a nightmare if we lose the game on AI inference to them as well. That is why I believe ‚ÄúTensor helps us build ethical AI‚Äù is a double-edged sword.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(para)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odCm7VT9fOrt",
        "outputId": "e6dc6523-ca84-42be-abfe-985de2fad4d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2602"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document=\"We are learning tokenization in NPL\"   #Example\n",
        "nltk.word_tokenize(document)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5pizmQKfOuS",
        "outputId": "e495053c-73ef-4556-d00a-5ca273c84baa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['We', 'are', 'learning', 'tokenization', 'in', 'NPL']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentence Tokenization\n",
        "sent=nltk.sent_tokenize(para)"
      ],
      "metadata": {
        "id": "bG7jXhLUfOw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpzQRqKVfOzk",
        "outputId": "7e81e294-e00f-4328-d81c-46c2cc261aa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mUlcHyfMfO2H",
        "outputId": "af488f0a-9d79-4d7c-e83f-790467680378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'‚Äî Tensor and Tensorflow: A powerful combo üí™\\nThe Google Brain team developed an advanced AI framework named Tensorflow years back.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SxaplU8kfO4c",
        "outputId": "fd9af7a0-2134-4ade-e5fd-37249b90d685"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'After that, Google designed its own processing unit named Tensor Processing Unit or TPU to perform more efficiently with the Tensorflow.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Cleaning\n",
        "corpus=[]\n",
        "for i in range(len(sent)):\n",
        "  txt=re.sub('[^a-zA-Z]',' ',sent[i])\n",
        "  txt=txt.lower()\n",
        "  corpus.append(txt)"
      ],
      "metadata": {
        "id": "74-Dr1o9fO61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "id": "r8j9KOCJfO9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Stemming\n",
        "stemmer=PorterStemmer()"
      ],
      "metadata": {
        "id": "24WZhVBGfPAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer.stem('goes') # Examples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "khIc-yPBfPDE",
        "outputId": "ec139f5e-e917-4be8-e871-9c27e3e2b167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'goe'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer.stem('history') # Examples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VFJz9UJTfPFl",
        "outputId": "b1b00bca-8a2d-4b56-e4f8-b4187eb4b147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'histori'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer.stem('finally') # Examples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oWxsyD0EfPIA",
        "outputId": "0288d49f-52d5-4309-fe22-ecd13f98451f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'final'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in corpus:\n",
        "  words=nltk.word_tokenize(i)\n",
        "  print(words)"
      ],
      "metadata": {
        "id": "DL5-95d5fPKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming and remove stop words\n",
        "for i in corpus:\n",
        "  words=nltk.word_tokenize(i)\n",
        "  for i in words:\n",
        "    if i not in set(stopwords.words(\"english\")):\n",
        "      print(stemmer.stem(i))"
      ],
      "metadata": {
        "id": "hJgl-MEofPNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatization\n",
        "lemma=WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "Em1GmJ02mH3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemma.lemmatize(\"google\")  #Example"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "URh-dYPEmH6T",
        "outputId": "969f8901-bd8a-48c8-930c-144ea5dc34c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'google'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemma.lemmatize(\"historically\")  #Example"
      ],
      "metadata": {
        "id": "snZJEnw0mH9F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "592f5d16-215c-4f72-a594-5209f566a437"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'historically'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemma.lemmatize(\"coming\")  #Example"
      ],
      "metadata": {
        "id": "FqETV3oomIAC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5b323d1f-1b71-4cdb-ebdb-1e8ec063082f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'coming'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in corpus:\n",
        "  words=nltk.word_tokenize(i)\n",
        "  for i in words:\n",
        "    if i not in set(stopwords.words(\"english\")):\n",
        "      print(lemma.lemmatize(i))"
      ],
      "metadata": {
        "id": "pFeeVZ5jmIDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FEATURE EXTRACTION"
      ],
      "metadata": {
        "id": "Ie-iM-G8dCJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer"
      ],
      "metadata": {
        "id": "Hc42Q0RncXxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv=CountVectorizer()\n",
        "#cv=CountVectorizer()\n",
        "x=cv.fit_transform(corpus)\n",
        "cv.vocabulary_"
      ],
      "metadata": {
        "id": "-pTax8PIcX1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x[0].toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4AR3vQZcX8V",
        "outputId": "dd6f32ea-0eca-4903-a935-d6d599a66878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 1, 0, 0, 1, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ttrRfWNOeb2y",
        "outputId": "64e33097-5ec2-47ec-e142-9956fc0d7c3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'  tensor and tensorflow  a powerful combo   the google brain team developed an advanced ai framework named tensorflow years back '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert array into dataframe\n",
        "x=pd.DataFrame(x.toarray(),columns=cv.get_feature_names_out())\n",
        "x"
      ],
      "metadata": {
        "id": "M4EBHp5ceb6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TF-IDF"
      ],
      "metadata": {
        "id": "NGnz9_hWg-Ad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf=TfidfVectorizer()\n",
        "x=tf.fit_transform(corpus)"
      ],
      "metadata": {
        "id": "RD4l9S6Neb8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.toarray()"
      ],
      "metadata": {
        "id": "wSCSbiq_mIOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=pd.DataFrame(x.toarray(),columns=tf.get_feature_names_out())\n",
        "x"
      ],
      "metadata": {
        "id": "lDEctBJYhNJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knM39XDOhdhY",
        "outputId": "1db64f2f-2ddf-47ad-c475-aa8064cefe0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29, 216)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.get_feature_names_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zctEbaRzhjU2",
        "outputId": "b4f365c4-acd6-4916-a516-0145960dda0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['about', 'advanced', 'advancement', 'after', 'ai', 'all', 'almost',\n",
              "       'alphago', 'also', 'am', 'an', 'and', 'are', 'article', 'as',\n",
              "       'aspects', 'back', 'be', 'because', 'believe', 'billions', 'binds',\n",
              "       'blinkai', 'brain', 'build', 'by', 'can', 'changing', 'chip',\n",
              "       'chips', 'choices', 'cloud', 'club', 'combination', 'combo',\n",
              "       'companies', 'compete', 'components', 'computation', 'concern',\n",
              "       'constraints', 'consumption', 'cool', 'could', 'create', 'crucial',\n",
              "       'currently', 'data', 'days', 'defeated', 'design', 'designed',\n",
              "       'details', 'developed', 'devices', 'don', 'double', 'edge',\n",
              "       'edged', 'efficacy', 'efficiently', 'engine', 'engineering',\n",
              "       'entrance', 'ethical', 'even', 'exactly', 'existing', 'expedited',\n",
              "       'expert', 'fast', 'floor', 'foghorn', 'for', 'framework', 'from',\n",
              "       'further', 'game', 'get', 'giant', 'go', 'google', 'graph', 'hand',\n",
              "       'harder', 'hardware', 'has', 'have', 'helps', 'how', 'however',\n",
              "       'huge', 'human', 'if', 'in', 'including', 'industry', 'inference',\n",
              "       'into', 'invention', 'is', 'isn', 'it', 'its', 'kick', 'kudos',\n",
              "       'large', 'latest', 'learning', 'lose', 'lost', 'low', 'machine',\n",
              "       'make', 'manufacturing', 'many', 'market', 'may', 'methodology',\n",
              "       'milestone', 'millions', 'model', 'models', 'more', 'must',\n",
              "       'named', 'nature', 'nevertheless', 'new', 'next', 'nightmare',\n",
              "       'no', 'not', 'number', 'of', 'on', 'opportunity', 'or', 'other',\n",
              "       'outcome', 'own', 'parameters', 'perform', 'performance',\n",
              "       'performing', 'physical', 'place', 'placement', 'planning',\n",
              "       'player', 'power', 'powerful', 'privacy', 'processing',\n",
              "       'professional', 'project', 'published', 'real', 'referred',\n",
              "       'remember', 'requirements', 'revolution', 'running', 'same',\n",
              "       'satisfied', 'see', 'sent', 'series', 'significantly',\n",
              "       'smartphones', 'software', 'started', 'statement', 'step', 'story',\n",
              "       'such', 'sword', 'team', 'tech', 'technology', 'tensor',\n",
              "       'tensorflow', 'that', 'the', 'their', 'them', 'there', 'they',\n",
              "       'this', 'tightly', 'titles', 'to', 'tpu', 'training', 'try',\n",
              "       'unit', 'us', 'used', 'users', 'using', 'various', 'want', 'was',\n",
              "       'we', 'welcome', 'well', 'when', 'where', 'while', 'why', 'will',\n",
              "       'with', 'working', 'would', 'years', 'you'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tf.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7zHkbnIhjXg",
        "outputId": "b6d9f851-b802-4922-b233-58019a34157c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "216"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Ry6868dhjZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wj0-l_pbhjbp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}